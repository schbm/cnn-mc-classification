{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The dataset comes already with a train, validation and test split.\n",
    "\n",
    "The training data contains 2000 images per class with 256x256 pixels per picture.\n",
    "The validation set contains 100/200 images per class\n",
    "and the testing data is filled with a random number\n",
    "of images per class.\n",
    "\n",
    "Since the project requires to have atleast 500 images per class and that 30% should be locked for the test set, \n",
    "we will only use the data contained in the training set and split it ourselves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set os env variable. Only required if not already set.\n",
    "os.environ[\"aiap_data_path\"] = \"C:/Users/mrcls/temp_dataset/animals/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.environ[\"aiap_data_path\"]\n",
    "batch_size = 32\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "classes = [ #explicitly define the used classes to avoid errors\n",
    "    \"Cow\",\n",
    "    \"Dog\",\n",
    "    \"Elephant\",\n",
    "    \"Gorilla\",\n",
    "    \"Hippo\",\n",
    "    \"Lizard\",\n",
    "    \"Monkey\",\n",
    "    \"Panda\",\n",
    "    \"Tiger\",\n",
    "    \"Zebra\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 10 classes.\n",
      "Using 14000 files for training.\n",
      "Using 6000 files for validation.\n",
      "do not confuse the output here. we explicitly use the validation data as test data and split the training data again for the validation data\n"
     ]
    }
   ],
   "source": [
    "#Load the data and split\n",
    "#A tf.data.Dataset object\n",
    "data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_path, #directory where data is located\n",
    "    class_names=classes, #pass in names of classes\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle=True, #shuffle the data\n",
    "    seed=1234, #seed for the shuffling and transformations\n",
    "    validation_split=0.3, #we reserve 30% of the data for the test set\n",
    "    subset=\"both\",\n",
    ")\n",
    "print(\"do not confuse the output here. we explicitly use the validation data as test data and split the training data again for the validation data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data variable contains: 2 elements\n",
      "training data size: tf.Tensor(438, shape=(), dtype=int64)\n",
      "test data size: tf.Tensor(188, shape=(), dtype=int64)\n",
      "class names: ['Cow', 'Dog', 'Elephant', 'Gorilla', 'Hippo', 'Lizard', 'Monkey', 'Panda', 'Tiger', 'Zebra']\n"
     ]
    }
   ],
   "source": [
    "print(\"data variable contains:\",len(data),\"elements\")\n",
    "training_data= data[0]\n",
    "test_data = data[1]\n",
    "assert isinstance(training_data, tf.data.Dataset)\n",
    "assert isinstance(test_data, tf.data.Dataset)\n",
    "\n",
    "print(\"training data size:\",training_data.cardinality())\n",
    "print(\"test data size:\", test_data.cardinality())\n",
    "print(\"class names:\", training_data.class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in training_data.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(training_data.class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miniproj2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
