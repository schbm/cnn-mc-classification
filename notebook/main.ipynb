{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "We used the dataset  from Kaggle [Animal Species Classification - V3](https://www.kaggle.com/datasets/utkarshsaxenadn/animal-image-classification-dataset).\n",
    "The authors created it to to have a data set for classifying animal species.\n",
    "It is licensed under the \"CC0: Public Domain\" license.\n",
    "\n",
    "The dataset comes already with a train, validation and test split for a total of 15 different animal classes.\n",
    "The training data contains 2000 images per class with 256x256 pixels per picture.\n",
    "The validation set contains 100/200 images per class\n",
    "and the testing data is filled with a random number\n",
    "of images per class.\n",
    "\n",
    "Since the project requires to have atleast 500 images per class and that 30% should be locked for the test set, \n",
    "we will only use the data contained in the training set and split it ourselves.\n",
    "In the following code segments we split the data to 0.3 test and 0.7 training data.\n",
    "From the 0.8 training data we split it again to reserve data for validation.\n",
    "We use a hardcoded seed to ensure the same shuffle.\n",
    "The training was precleaned to only contain the data directories for the 10 classes used in this project."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T08:20:53.274912Z",
     "start_time": "2024-04-30T08:20:53.270475Z"
    }
   },
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' #Workaround for kernel crash because multiple copies of the OpenMP runtime have been linked\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T08:21:02.924583Z",
     "start_time": "2024-04-30T08:21:02.920531Z"
    }
   },
   "source": [
    "#Set os env variable. Only required if not already set.\n",
    "#This should point to the folder which contains the training data\n",
    "os.environ[\"aiap_data_path\"] = \"/home/musa/Downloads/archive/Training Data/Training Data\""
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T08:21:09.088475Z",
     "start_time": "2024-04-30T08:21:09.083755Z"
    }
   },
   "source": [
    "data_path = os.environ[\"aiap_data_path\"]\n",
    "batch_size = 32 # the whole data will be split into a total of the amount of batches\n",
    "img_height = 64 # The image will be resized when imported to this height\n",
    "img_width = 64 # The image will be resized when imported to this width\n",
    "img_channels = 3 #RGB\n",
    "shuffle_seed = 1234 # The seed for the data shuffle\n",
    "shuffle_enabled = True\n",
    "test_data_ratio = 0.3\n",
    "validation_data_ratio= 0.2\n",
    "img_classes = [ #explicitly defined to avoid errors\n",
    "    \"Cow\",\n",
    "    \"Dog\",\n",
    "    \"Elephant\",\n",
    "    \"Gorilla\",\n",
    "    \"Hippo\",\n",
    "    \"Lizard\",\n",
    "    \"Monkey\",\n",
    "    \"Panda\",\n",
    "    \"Tiger\",\n",
    "    \"Zebra\"\n",
    "    ]\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T08:21:16.675222Z",
     "start_time": "2024-04-30T08:21:15.611923Z"
    }
   },
   "source": [
    "#Load the data and split it to training & test\n",
    "data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_path, #directory where data is located\n",
    "    class_names=img_classes, #pass in names of classes\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle=shuffle_enabled, #shuffle the data\n",
    "    seed=shuffle_seed, #seed for the shuffling and transformations\n",
    "    validation_split=test_data_ratio, #we reserve a ratio of the data for the test set\n",
    "    subset=\"both\", #return both test & training set\n",
    ")\n",
    "print(\"do not confuse the output here. we explicitly use the validation data as test data and split the training data again for the validation data\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 10 classes.\n",
      "Using 14000 files for training.\n",
      "Using 6000 files for validation.\n",
      "do not confuse the output here. we explicitly use the validation data as test data and split the training data again for the validation data\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T08:23:35.503173Z",
     "start_time": "2024-04-30T08:23:35.497049Z"
    }
   },
   "source": [
    "# print information about the data\n",
    "print(\"data variable contains:\",len(data),\"elements\")\n",
    "training_data= data[0]\n",
    "test_data = data[1]\n",
    "assert isinstance(training_data, tf.data.Dataset)\n",
    "assert isinstance(test_data, tf.data.Dataset)\n",
    "print(\"training data size:\",training_data.cardinality())\n",
    "print(\"test data size:\", test_data.cardinality())\n",
    "print(\"class names:\", training_data.class_names)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data variable contains: 2 elements\n",
      "training data size: tf.Tensor(438, shape=(), dtype=int64)\n",
      "test data size: tf.Tensor(188, shape=(), dtype=int64)\n",
      "class names: ['Cow', 'Dog', 'Elephant', 'Gorilla', 'Hippo', 'Lizard', 'Monkey', 'Panda', 'Tiger', 'Zebra']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T08:23:39.935077Z",
     "start_time": "2024-04-30T08:23:38.311933Z"
    }
   },
   "source": [
    "# finally split the current training data into a separate validation set\n",
    "training_data_size = sum(1 for _ in training_data)\n",
    "print(training_data_size, \"batches\")\n",
    "validation_data_size = int(validation_data_ratio * training_data_size)\n",
    "print(validation_data_size, \"batches\")\n",
    "validation_data = training_data.take(validation_data_size)\n",
    "class_names = training_data.class_names\n",
    "training_data = training_data.skip(validation_data_size)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438 batches\n",
      "87 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 10:23:39.928757: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data\n",
    "OFFLOAD TO TENSORFLOW FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T08:23:44.628740Z",
     "start_time": "2024-04-30T08:23:44.328356Z"
    }
   },
   "source": [
    "# Print the shape of the input data\n",
    "print(\"Shape of training data:\")\n",
    "i = 0\n",
    "for x, y in training_data:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(\"True label:\", y[0])\n",
    "    i=i+1\n",
    "    if i>3:\n",
    "        break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:\n",
      "(32, 64, 64, 3)\n",
      "(32,)\n",
      "True label: tf.Tensor(7, shape=(), dtype=int32)\n",
      "(32, 64, 64, 3)\n",
      "(32,)\n",
      "True label: tf.Tensor(2, shape=(), dtype=int32)\n",
      "(32, 64, 64, 3)\n",
      "(32,)\n",
      "True label: tf.Tensor(0, shape=(), dtype=int32)\n",
      "(32, 64, 64, 3)\n",
      "(32,)\n",
      "True label: tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T08:23:48.631771Z",
     "start_time": "2024-04-30T08:23:48.384055Z"
    }
   },
   "source": [
    "def printPixelValueRange(dataset):\n",
    "    for image, _ in dataset.take(1):\n",
    "        print(f\"Max value: {np.max(image[0])}\")\n",
    "printPixelValueRange(training_data)\n",
    "printPixelValueRange(validation_data)\n",
    "printPixelValueRange(test_data)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value: 255.0\n",
      "Max value: 253.0\n",
      "Max value: 254.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 10:23:48.596834: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-04-30 10:23:48.613726: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-04-30 10:23:48.628946: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T08:23:53.262703Z",
     "start_time": "2024-04-30T08:23:52.927368Z"
    }
   },
   "source": [
    "def normalize(image,label):\n",
    "    image = tf.cast(image/255.0 ,tf.float32)\n",
    "    return image,label\n",
    "\n",
    "training_data = training_data.map(normalize)\n",
    "validation_data = validation_data.map(normalize)\n",
    "test_data = test_data.map(normalize)\n",
    "\n",
    "\n",
    "printPixelValueRange(training_data)\n",
    "printPixelValueRange(validation_data)\n",
    "printPixelValueRange(test_data)\n",
    "\n",
    "# todo Run up until here--"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value: 1.0\n",
      "Max value: 1.0\n",
      "Max value: 0.9970588088035583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 10:23:53.213212: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-04-30 10:23:53.236758: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-04-30 10:23:53.259773: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize counters for each class\n",
    "class_counts_training = {class_name: 0 for class_name in class_names}\n",
    "class_counts_validation = {class_name: 0 for class_name in class_names}\n",
    "class_counts_test = {class_name: 0 for class_name in class_names}\n",
    "\n",
    "# Iterate through the dataset to count occurrences of each class\n",
    "for batch in training_data:\n",
    "    labels = batch[1]  # Assuming labels are in the second element of each batch\n",
    "    for label in labels:\n",
    "        class_counts_training[class_names[label]] += 1\n",
    "\n",
    "for batch in validation_data:\n",
    "    labels = batch[1]  # Assuming labels are in the second element of each batch\n",
    "    for label in labels:\n",
    "        class_counts_validation[class_names[label]] += 1\n",
    "\n",
    "for batch in test_data:\n",
    "    labels = batch[1]  # Assuming labels are in the second element of each batch\n",
    "    for label in labels:\n",
    "        class_counts_test[class_names[label]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the class distribution\n",
    "fig, (sub1, sub2, sub3) = plt.subplots(3, 1, figsize=(10, 10))\n",
    "# Adjust the spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "sub1.bar(class_counts_training.keys(), class_counts_training.values())\n",
    "sub1.set_xlabel('Class')\n",
    "sub1.set_ylabel('Count')\n",
    "sub1.set_title('Class Distribution of Training Data')\n",
    "\n",
    "sub2.bar(class_counts_validation.keys(), class_counts_validation.values())\n",
    "sub2.set_xlabel('Class')\n",
    "sub2.set_ylabel('Count')\n",
    "sub2.set_title('Class Distribution of Validation Data')\n",
    "\n",
    "sub3.bar(class_counts_test.keys(), class_counts_test.values())\n",
    "sub3.set_xlabel('Class')\n",
    "sub3.set_ylabel('Count')\n",
    "sub3.set_title('Class Distribution of Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Classes Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "print(vars(training_data))\n",
    "for images, labels in training_data.take(1): # takes one batch\n",
    "  for i in range(25):\n",
    "    try:\n",
    "      ax = plt.subplot(5, 5, i + 1)\n",
    "      plt.imshow(images[i]) #.numpy().astype(\"uint8\")\n",
    "      plt.title(class_names[labels[i]])\n",
    "      plt.axis(\"off\")\n",
    "    except Exception as e:\n",
    "      print(f\"Error at index {i}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis\n",
    "Analyse and visualize your data set. How many samples per class do you have? Is the dataset \n",
    "balanced? Plot a few images. What is the range of values of the images? If it is [0 255] you need to \n",
    "scale or normalize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture 1\n",
    "- 3 layers (without MaxPooling and Flatten)\n",
    "- <2000 trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 1, 1, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,282\n",
      "Trainable params: 2,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_model = models.Sequential()\n",
    "simple_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, img_channels)))\n",
    "simple_model.add(layers.MaxPooling2D((32, 32)))\n",
    "simple_model.add(layers.Flatten())\n",
    "simple_model.add(layers.Dense(32, activation='relu'))\n",
    "simple_model.add(layers.Dense(10))\n",
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history dictionary for successive combined trainings\n",
    "combined_history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save history data to disk\n",
    "import json\n",
    "# Save the dictionary to disk using JSON\n",
    "with open('combined_history_simple_model.json', 'w') as f:\n",
    "    json.dump(combined_history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load history data from disk\n",
    "import json\n",
    "\n",
    "with open('combined_history_simple_model.json', 'r') as f:\n",
    "    combined_history = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 5s 12ms/step - loss: 2.1898 - accuracy: 0.2123 - val_loss: 2.0294 - val_accuracy: 0.2942\n",
      "Epoch 2/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.9433 - accuracy: 0.3119 - val_loss: 1.8775 - val_accuracy: 0.3261\n",
      "Epoch 3/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.8449 - accuracy: 0.3468 - val_loss: 1.8122 - val_accuracy: 0.3495\n",
      "Epoch 4/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.8019 - accuracy: 0.3590 - val_loss: 1.7990 - val_accuracy: 0.3470\n",
      "Epoch 5/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.7741 - accuracy: 0.3724 - val_loss: 1.7553 - val_accuracy: 0.3757\n",
      "Epoch 6/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.7554 - accuracy: 0.3814 - val_loss: 1.7430 - val_accuracy: 0.3879\n",
      "Epoch 7/100\n",
      "351/351 [==============================] - 5s 14ms/step - loss: 1.7389 - accuracy: 0.3849 - val_loss: 1.7425 - val_accuracy: 0.3757\n",
      "Epoch 8/100\n",
      "351/351 [==============================] - 5s 14ms/step - loss: 1.7276 - accuracy: 0.3928 - val_loss: 1.7263 - val_accuracy: 0.3948\n",
      "Epoch 9/100\n",
      "351/351 [==============================] - 5s 14ms/step - loss: 1.7138 - accuracy: 0.4025 - val_loss: 1.7027 - val_accuracy: 0.4005\n",
      "Epoch 10/100\n",
      "351/351 [==============================] - 5s 14ms/step - loss: 1.7027 - accuracy: 0.4082 - val_loss: 1.7062 - val_accuracy: 0.4034\n",
      "Epoch 11/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.6965 - accuracy: 0.4091 - val_loss: 1.6946 - val_accuracy: 0.4084\n",
      "Epoch 12/100\n",
      "351/351 [==============================] - 5s 14ms/step - loss: 1.6828 - accuracy: 0.4178 - val_loss: 1.6849 - val_accuracy: 0.4098\n",
      "Epoch 13/100\n",
      "351/351 [==============================] - 6s 14ms/step - loss: 1.6798 - accuracy: 0.4206 - val_loss: 1.6714 - val_accuracy: 0.4228\n",
      "Epoch 14/100\n",
      "351/351 [==============================] - 6s 14ms/step - loss: 1.6663 - accuracy: 0.4250 - val_loss: 1.6884 - val_accuracy: 0.4246\n",
      "Epoch 15/100\n",
      "351/351 [==============================] - 5s 14ms/step - loss: 1.6640 - accuracy: 0.4253 - val_loss: 1.6660 - val_accuracy: 0.4285\n",
      "Epoch 16/100\n",
      "351/351 [==============================] - 5s 14ms/step - loss: 1.6531 - accuracy: 0.4282 - val_loss: 1.6548 - val_accuracy: 0.4397\n",
      "Epoch 17/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.6412 - accuracy: 0.4375 - val_loss: 1.6453 - val_accuracy: 0.4411\n",
      "Epoch 18/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.6377 - accuracy: 0.4396 - val_loss: 1.6430 - val_accuracy: 0.4418\n",
      "Epoch 19/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.6302 - accuracy: 0.4409 - val_loss: 1.6586 - val_accuracy: 0.4393\n",
      "Epoch 20/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.6222 - accuracy: 0.4454 - val_loss: 1.6440 - val_accuracy: 0.4432\n",
      "Epoch 21/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.6182 - accuracy: 0.4493 - val_loss: 1.6318 - val_accuracy: 0.4440\n",
      "Epoch 22/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.6111 - accuracy: 0.4486 - val_loss: 1.6252 - val_accuracy: 0.4458\n",
      "Epoch 23/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.6018 - accuracy: 0.4520 - val_loss: 1.6154 - val_accuracy: 0.4458\n",
      "Epoch 24/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.5935 - accuracy: 0.4566 - val_loss: 1.6071 - val_accuracy: 0.4551\n",
      "Epoch 25/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.5856 - accuracy: 0.4611 - val_loss: 1.6056 - val_accuracy: 0.4573\n",
      "Epoch 26/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.5816 - accuracy: 0.4611 - val_loss: 1.5964 - val_accuracy: 0.4558\n",
      "Epoch 27/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.5721 - accuracy: 0.4656 - val_loss: 1.5977 - val_accuracy: 0.4637\n",
      "Epoch 28/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.5672 - accuracy: 0.4667 - val_loss: 1.6034 - val_accuracy: 0.4526\n",
      "Epoch 29/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.5651 - accuracy: 0.4694 - val_loss: 1.5972 - val_accuracy: 0.4608\n",
      "Epoch 30/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.5561 - accuracy: 0.4691 - val_loss: 1.5838 - val_accuracy: 0.4598\n",
      "Epoch 31/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.5518 - accuracy: 0.4701 - val_loss: 1.5844 - val_accuracy: 0.4594\n",
      "Epoch 32/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.5497 - accuracy: 0.4749 - val_loss: 1.5772 - val_accuracy: 0.4756\n",
      "Epoch 33/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.5429 - accuracy: 0.4757 - val_loss: 1.5774 - val_accuracy: 0.4619\n",
      "Epoch 34/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.5334 - accuracy: 0.4786 - val_loss: 1.5861 - val_accuracy: 0.4626\n",
      "Epoch 35/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.5370 - accuracy: 0.4790 - val_loss: 1.5794 - val_accuracy: 0.4709\n",
      "Epoch 36/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.5245 - accuracy: 0.4825 - val_loss: 1.5668 - val_accuracy: 0.4666\n",
      "Epoch 37/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.5237 - accuracy: 0.4847 - val_loss: 1.5753 - val_accuracy: 0.4684\n",
      "Epoch 38/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.5243 - accuracy: 0.4847 - val_loss: 1.5749 - val_accuracy: 0.4662\n",
      "Epoch 39/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.5139 - accuracy: 0.4842 - val_loss: 1.6178 - val_accuracy: 0.4637\n",
      "Epoch 40/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.5175 - accuracy: 0.4864 - val_loss: 1.5812 - val_accuracy: 0.4734\n",
      "Epoch 41/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.5110 - accuracy: 0.4885 - val_loss: 1.5488 - val_accuracy: 0.4770\n",
      "Epoch 42/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.5033 - accuracy: 0.4910 - val_loss: 1.5471 - val_accuracy: 0.4802\n",
      "Epoch 43/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.5022 - accuracy: 0.4921 - val_loss: 1.5562 - val_accuracy: 0.4802\n",
      "Epoch 44/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.4979 - accuracy: 0.4896 - val_loss: 1.5678 - val_accuracy: 0.4749\n",
      "Epoch 45/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4963 - accuracy: 0.4952 - val_loss: 1.5420 - val_accuracy: 0.4824\n",
      "Epoch 46/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4905 - accuracy: 0.4947 - val_loss: 1.5665 - val_accuracy: 0.4784\n",
      "Epoch 47/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4901 - accuracy: 0.4966 - val_loss: 1.5714 - val_accuracy: 0.4734\n",
      "Epoch 48/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.4899 - accuracy: 0.4968 - val_loss: 1.5325 - val_accuracy: 0.4795\n",
      "Epoch 49/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4887 - accuracy: 0.4996 - val_loss: 1.5406 - val_accuracy: 0.4828\n",
      "Epoch 50/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.4848 - accuracy: 0.4966 - val_loss: 1.5582 - val_accuracy: 0.4759\n",
      "Epoch 51/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4818 - accuracy: 0.4995 - val_loss: 1.5813 - val_accuracy: 0.4752\n",
      "Epoch 52/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4782 - accuracy: 0.5006 - val_loss: 1.5500 - val_accuracy: 0.4795\n",
      "Epoch 53/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4802 - accuracy: 0.4966 - val_loss: 1.5312 - val_accuracy: 0.4885\n",
      "Epoch 54/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.4724 - accuracy: 0.5003 - val_loss: 1.5528 - val_accuracy: 0.4774\n",
      "Epoch 55/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4720 - accuracy: 0.5004 - val_loss: 1.5676 - val_accuracy: 0.4738\n",
      "Epoch 56/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4642 - accuracy: 0.5078 - val_loss: 1.5422 - val_accuracy: 0.4846\n",
      "Epoch 57/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.4673 - accuracy: 0.5026 - val_loss: 1.5412 - val_accuracy: 0.4846\n",
      "Epoch 58/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.4633 - accuracy: 0.5053 - val_loss: 1.5449 - val_accuracy: 0.4802\n",
      "Epoch 59/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.4590 - accuracy: 0.5095 - val_loss: 1.5312 - val_accuracy: 0.4860\n",
      "Epoch 60/100\n",
      "351/351 [==============================] - 5s 14ms/step - loss: 1.4607 - accuracy: 0.5062 - val_loss: 1.5675 - val_accuracy: 0.4781\n",
      "Epoch 61/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.4560 - accuracy: 0.5051 - val_loss: 1.5334 - val_accuracy: 0.4878\n",
      "Epoch 62/100\n",
      "351/351 [==============================] - 5s 14ms/step - loss: 1.4543 - accuracy: 0.5112 - val_loss: 1.5323 - val_accuracy: 0.4889\n",
      "Epoch 63/100\n",
      "351/351 [==============================] - 6s 16ms/step - loss: 1.4561 - accuracy: 0.5111 - val_loss: 1.5152 - val_accuracy: 0.4914\n",
      "Epoch 64/100\n",
      "351/351 [==============================] - 5s 14ms/step - loss: 1.4527 - accuracy: 0.5119 - val_loss: 1.5185 - val_accuracy: 0.4943\n",
      "Epoch 65/100\n",
      "351/351 [==============================] - 5s 14ms/step - loss: 1.4498 - accuracy: 0.5111 - val_loss: 1.5425 - val_accuracy: 0.4831\n",
      "Epoch 66/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4472 - accuracy: 0.5128 - val_loss: 1.5452 - val_accuracy: 0.4864\n",
      "Epoch 67/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4469 - accuracy: 0.5072 - val_loss: 1.5311 - val_accuracy: 0.4896\n",
      "Epoch 68/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.4449 - accuracy: 0.5075 - val_loss: 1.5093 - val_accuracy: 0.4896\n",
      "Epoch 69/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4468 - accuracy: 0.5112 - val_loss: 1.5297 - val_accuracy: 0.4899\n",
      "Epoch 70/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4442 - accuracy: 0.5145 - val_loss: 1.5273 - val_accuracy: 0.4957\n",
      "Epoch 71/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4419 - accuracy: 0.5116 - val_loss: 1.5329 - val_accuracy: 0.4867\n",
      "Epoch 72/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4435 - accuracy: 0.5129 - val_loss: 1.5267 - val_accuracy: 0.4896\n",
      "Epoch 73/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4401 - accuracy: 0.5136 - val_loss: 1.5252 - val_accuracy: 0.4889\n",
      "Epoch 74/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.4382 - accuracy: 0.5157 - val_loss: 1.5141 - val_accuracy: 0.4914\n",
      "Epoch 75/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4350 - accuracy: 0.5155 - val_loss: 1.5168 - val_accuracy: 0.4921\n",
      "Epoch 76/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4376 - accuracy: 0.5114 - val_loss: 1.5834 - val_accuracy: 0.4691\n",
      "Epoch 77/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4310 - accuracy: 0.5160 - val_loss: 1.5582 - val_accuracy: 0.4824\n",
      "Epoch 78/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4354 - accuracy: 0.5156 - val_loss: 1.5415 - val_accuracy: 0.4813\n",
      "Epoch 79/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4288 - accuracy: 0.5137 - val_loss: 1.5087 - val_accuracy: 0.4917\n",
      "Epoch 80/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4258 - accuracy: 0.5198 - val_loss: 1.5210 - val_accuracy: 0.4903\n",
      "Epoch 81/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4238 - accuracy: 0.5226 - val_loss: 1.5245 - val_accuracy: 0.4878\n",
      "Epoch 82/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4252 - accuracy: 0.5175 - val_loss: 1.5143 - val_accuracy: 0.4982\n",
      "Epoch 83/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4254 - accuracy: 0.5200 - val_loss: 1.5204 - val_accuracy: 0.4864\n",
      "Epoch 84/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4201 - accuracy: 0.5200 - val_loss: 1.5171 - val_accuracy: 0.4892\n",
      "Epoch 85/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4247 - accuracy: 0.5198 - val_loss: 1.5521 - val_accuracy: 0.4806\n",
      "Epoch 86/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4178 - accuracy: 0.5226 - val_loss: 1.5199 - val_accuracy: 0.4957\n",
      "Epoch 87/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4224 - accuracy: 0.5231 - val_loss: 1.5000 - val_accuracy: 0.4935\n",
      "Epoch 88/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.4176 - accuracy: 0.5214 - val_loss: 1.5309 - val_accuracy: 0.4928\n",
      "Epoch 89/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.4153 - accuracy: 0.5207 - val_loss: 1.5508 - val_accuracy: 0.4867\n",
      "Epoch 90/100\n",
      "351/351 [==============================] - 6s 15ms/step - loss: 1.4155 - accuracy: 0.5230 - val_loss: 1.5068 - val_accuracy: 0.4964\n",
      "Epoch 91/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.4150 - accuracy: 0.5234 - val_loss: 1.5112 - val_accuracy: 0.5004\n",
      "Epoch 92/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4165 - accuracy: 0.5203 - val_loss: 1.5082 - val_accuracy: 0.4996\n",
      "Epoch 93/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4135 - accuracy: 0.5205 - val_loss: 1.5150 - val_accuracy: 0.4964\n",
      "Epoch 94/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4129 - accuracy: 0.5252 - val_loss: 1.5368 - val_accuracy: 0.4910\n",
      "Epoch 95/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4112 - accuracy: 0.5246 - val_loss: 1.5159 - val_accuracy: 0.5022\n",
      "Epoch 96/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4050 - accuracy: 0.5277 - val_loss: 1.4944 - val_accuracy: 0.5050\n",
      "Epoch 97/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4073 - accuracy: 0.5275 - val_loss: 1.4974 - val_accuracy: 0.4950\n",
      "Epoch 98/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4034 - accuracy: 0.5268 - val_loss: 1.5217 - val_accuracy: 0.4968\n",
      "Epoch 99/100\n",
      "351/351 [==============================] - 5s 12ms/step - loss: 1.4080 - accuracy: 0.5261 - val_loss: 1.5205 - val_accuracy: 0.4960\n",
      "Epoch 100/100\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 1.4043 - accuracy: 0.5278 - val_loss: 1.5151 - val_accuracy: 0.5014\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = simple_model.fit(training_data, epochs=100, \n",
    "                           validation_data=validation_data)\n",
    "# Update the combined_history with the first training session\n",
    "for key in combined_history.keys():\n",
    "    combined_history[key].extend(history.history[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plott accuracy\n",
    "plt.plot(combined_history['accuracy'], label='accuracy')\n",
    "plt.plot(combined_history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot error\n",
    "plt.plot(combined_history['loss'], label = 'loss')\n",
    "plt.plot(combined_history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"validation data\",simple_model.evaluate(training_data))\n",
    "print(\"validation data\",simple_model.evaluate(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to disk\n",
    "simple_model.save(\"simple_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = tf.keras.models.load_model('simple_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "of the validation data.\n",
    "Make 3 different plots for 3 different values of the \n",
    "'normalize' parameter (see https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = np.array([])\n",
    "true_labels = np.array([])\n",
    "\n",
    "for x, y in training_data:\n",
    "    predicted_labels = np.concatenate([predicted_labels,\n",
    "                       np.argmax(simple_model(x), axis=-1)])\n",
    "    true_labels = np.concatenate([true_labels, y])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = simple_model.predict(training_data)\n",
    "#predicted_labels = np.argmax(predictions, axis=1) \n",
    "#true_labels = np.concatenate([y.numpy() for _, y in training_data], axis=0) \n",
    "cm = confusion_matrix(true_labels, predicted_labels) \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "disp.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_labels, predicted_labels, normalize='true') \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "disp.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_labels, predicted_labels, normalize='pred') \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "disp.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_labels, predicted_labels, normalize='all') \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "disp.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "Avoid stride>kernel-size (do you see why?)\n",
    "disscuss underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/a-guide-to-an-efficient-way-to-build-neural-network-architectures-part-ii-hyper-parameter-42efca01e5d7\n",
    "#If you think that a big amount of pixels are necessary for the network to recognize the object you will use large filters (as 11x11 or 9x9). \n",
    "#If you think what differentiates objects are some small and local features you should use small filters (3x3 or 5x5)\n",
    "# Note in general we use filters with odd sizes.\n",
    "\n",
    "#The basic principle followed in building a convolutional neural network is \n",
    "#to ‘keep the feature space wide and shallow in the initial stages of the network, and the make it narrower and deeper towards the end.’\n",
    "\n",
    "#Always start by using smaller filters is to collect as much local information as possible, and then gradually \n",
    "#increase the filter width to reduce the generated feature space width to represent more global, high-level and representative information\n",
    "\n",
    "# By convention the number of channels generally increase or stay the same while we progress through layers in our convolutional neural net architecture\n",
    "\n",
    "# Keep adding layers until you over-fit. \n",
    "#As once we achieved a considerable accuracy in our validation set we can use \n",
    "#regularization components like l1/l2 regularization, dropout, batch norm, data augmentation etc. to reduce over-fitting\n",
    "#https://medium.com/@charlottecullip/a-comparison-of-cnn-architectures-part-2-8d03c67d8ec6\n",
    "#https://www.geeksforgeeks.org/convolutional-neural-network-cnn-architectures/\n",
    "#https://medium.com/@sajals1146/alexnet-architecture-993b760dec86\n",
    "\n",
    "complex_model = models.Sequential()\n",
    "# first\n",
    "complex_model.add(layers.Conv2D(96, (6, 6),strides=2, activation='relu', input_shape=(img_height, img_width, img_channels)))\n",
    "complex_model.add(layers.BatchNormalization())\n",
    "# second\n",
    "complex_model.add(layers.Conv2D(128, (5, 5), padding='same', activation='relu'))\n",
    "complex_model.add(layers.BatchNormalization())\n",
    "# third\n",
    "complex_model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "complex_model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "complex_model.add(layers.BatchNormalization())\n",
    "#fourth\n",
    "complex_model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "complex_model.add(layers.BatchNormalization())\n",
    "#fifth\n",
    "complex_model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "complex_model.add(layers.BatchNormalization())\n",
    "complex_model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "#deep\n",
    "complex_model.add(layers.Flatten())\n",
    "complex_model.add(layers.Dense(512, activation='relu'))\n",
    "complex_model.add(layers.BatchNormalization())\n",
    "complex_model.add(layers.Dense(256, activation='relu'))\n",
    "complex_model.add(layers.BatchNormalization())\n",
    "complex_model.add(layers.Dense(10))\n",
    "complex_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history dictionary for successive combined trainings\n",
    "combined_complex_history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save history data to disk\n",
    "import json\n",
    "# Save the dictionary to disk using JSON\n",
    "with open('combined_history_complex_model.json', 'w') as f:\n",
    "    json.dump(combined_complex_history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load history data from disk\n",
    "import json\n",
    "\n",
    "with open('combined_history_complex_model.json', 'r') as f:\n",
    "    combined_complex_history = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T08:33:05.566039Z",
     "start_time": "2024-04-30T08:33:05.542661Z"
    }
   },
   "source": [
    "# train\n",
    "history = complex_model.fit(training_data, epochs=25, \n",
    "                           validation_data=validation_data)\n",
    "# Update the combined_history with the first training session\n",
    "for key in combined_complex_history.keys():\n",
    "    combined_complex_history[key].extend(history.history[key])"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'complex_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# train\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mcomplex_model\u001B[49m\u001B[38;5;241m.\u001B[39mfit(training_data, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m25\u001B[39m, \n\u001B[1;32m      3\u001B[0m                            validation_data\u001B[38;5;241m=\u001B[39mvalidation_data)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Update the combined_history with the first training session\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m combined_complex_history\u001B[38;5;241m.\u001B[39mkeys():\n",
      "\u001B[0;31mNameError\u001B[0m: name 'complex_model' is not defined"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T08:33:01.107797Z",
     "start_time": "2024-04-30T08:33:01.080837Z"
    }
   },
   "source": [
    "# plott accuracy\n",
    "plt.plot(combined_complex_history['accuracy'], label='accuracy')\n",
    "plt.plot(combined_complex_history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_complex_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# plott accuracy\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(\u001B[43mcombined_complex_history\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m], label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(combined_complex_history[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m], label \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'combined_complex_history' is not defined"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot error\n",
    "plt.plot(combined_complex_history['loss'], label = 'loss')\n",
    "plt.plot(combined_complex_history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"validation data\",complex_model.evaluate(training_data))\n",
    "print(\"validation data\",complex_model.evaluate(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to disk\n",
    "complex_model.save(\"complex_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_model = tf.keras.models.load_model('complex_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = complex_model.predict(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = np.array([])\n",
    "true_labels = np.array([])\n",
    "\n",
    "for x, y in training_data:\n",
    "    predicted_labels = np.concatenate([predicted_labels,\n",
    "                       np.argmax(complex_model(x), axis=-1)])\n",
    "    true_labels = np.concatenate([true_labels, y])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(true_labels)\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION: You cannot run the code like below (commented out),\n",
    "# since tensorflow will reshuffle the data so that true and predictions do not match anymore!!!!\n",
    "#predicted_labels = np.argmax(predictions, axis=-1) \n",
    "#print(predicted_labels)\n",
    "#true_labels = np.concatenate([y.numpy() for _, y in training_data], axis=0) \n",
    "#print(true_labels)\n",
    "cm = confusion_matrix(true_labels,predicted_labels) \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "disp.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_labels, predicted_labels, normalize='true') \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "disp.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) Plot a confusion matrix of the validation data. Make 3 different plots for 3 different values of the \n",
    "'normalize' parameter (see https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and train a second model. Increase the number of layers, number of filters (=kernels), the \n",
    "number of neurons in the dense layer etc. Make the network too complex such that you observe \n",
    "overfitting. Depending on the dataset, you may need in the order of 105 to 106 parameters to see \n",
    "overfitting. \n",
    "\n",
    "k) As before, plot learning curves and confusion matrix. Make sure you observe (and document) \n",
    "overfitting.\n",
    "\n",
    "l) Comment / discuss your model and the results."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T08:32:47.914889Z",
     "start_time": "2024-04-30T08:32:47.888391Z"
    }
   },
   "source": [
    "\n",
    "# Create a new model that includes only the layers up to the first convolutional layer\n",
    "layer_outputs = [layer.output for layer in complex_model.layers[:2]]\n",
    "activation_model = models.Model(inputs=complex_model.input, outputs=layer_outputs)\n",
    "\n",
    "# Load the first image from the dataset\n",
    "first_image = training_data.take(1)\n",
    "for image, _ in first_image:\n",
    "    img_tensor = image.numpy()\n",
    "    break  # break after taking the first image\n",
    "\n",
    "# Get activations\n",
    "activations = activation_model.predict(img_tensor)\n",
    "\n",
    "# Plot the first layer activations\n",
    "first_layer_activation = activations[0]\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(96):  # Assuming 96 filters in the first layer\n",
    "    plt.subplot(8, 12, i + 1)\n",
    "    plt.imshow(first_layer_activation[0, :, :, i], cmap='viridis')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'complex_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Create a new model that includes only the layers up to the first convolutional layer\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m layer_outputs \u001B[38;5;241m=\u001B[39m [layer\u001B[38;5;241m.\u001B[39moutput \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[43mcomplex_model\u001B[49m\u001B[38;5;241m.\u001B[39mlayers[:\u001B[38;5;241m2\u001B[39m]]\n\u001B[1;32m      3\u001B[0m activation_model \u001B[38;5;241m=\u001B[39m models\u001B[38;5;241m.\u001B[39mModel(inputs\u001B[38;5;241m=\u001B[39mcomplex_model\u001B[38;5;241m.\u001B[39minput, outputs\u001B[38;5;241m=\u001B[39mlayer_outputs)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Load the first image from the dataset\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'complex_model' is not defined"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture 3\n",
    "\n",
    "m) Make a copy of architecture 2 (that is, use exactly the same number of layers/neurons/kernels). \n",
    "Then optimize/regularize it:\n",
    "\n",
    "n) Add at least one dropout layer. Set the dropout-rate to a value between 0.1 and 0.5\n",
    "https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "\n",
    "o) Add L2 regularization to the Conv-Layers and to the Dense-Layers by setting the parameters\n",
    "kernel_regularizer=l2(lambda). Typical values for lambda are in the order of 10^-6 to 10^-3\n",
    "https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/\n",
    "\n",
    "p) Try different values for dropout-rate and lambda. Make sure you see a clear effect of regularization.\n",
    "Try and report the following: As a test, you can use very high values for lambda and dropout-rate; \n",
    "the network should underfit. For very small (zero) regularization parameters, the network should \n",
    "again overfit. The optimal values are somewhere between these extremes.\n",
    "\n",
    "q) Plot learning curves and confusion matrix \n",
    "\n",
    "r) Comment / discuss your model and the results.\n",
    "Note: It is possible that the overfitted network has a better accuracy than the regularized model \n",
    "(for reasons we will discuss in class). On the other hand, the loss should be lower."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T08:35:09.668372Z",
     "start_time": "2024-04-30T08:35:09.294666Z"
    }
   },
   "source": [
    "# https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "input_shape = (img_height, img_width, img_channels)\n",
    "complex_opt_model = models.Sequential()\n",
    "\n",
    "l2_lambda = 1e-5\n",
    "# first\n",
    "complex_opt_model.add(layers.Conv2D(96, (6, 6),strides=2, activation='relu' , kernel_regularizer=tf.keras.regularizers.l2(l2_lambda), input_shape=(img_height, img_width, img_channels)))\n",
    "complex_opt_model.add(layers.BatchNormalization())\n",
    "complex_opt_model.add(layers.Dropout(0.2))\n",
    "\n",
    "# second\n",
    "complex_opt_model.add(layers.Conv2D(128, (5, 5), padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_lambda)))\n",
    "complex_opt_model.add(layers.BatchNormalization())\n",
    "complex_opt_model.add(layers.Dropout(0.2))\n",
    "# third\n",
    "complex_opt_model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "complex_opt_model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_lambda)))\n",
    "complex_opt_model.add(layers.BatchNormalization())\n",
    "complex_opt_model.add(layers.Dropout(0.2))\n",
    "#fourth\n",
    "complex_opt_model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_lambda)))\n",
    "complex_opt_model.add(layers.BatchNormalization())\n",
    "complex_opt_model.add(layers.Dropout(0.2))\n",
    "#fifth\n",
    "complex_opt_model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_lambda)))\n",
    "complex_opt_model.add(layers.BatchNormalization())\n",
    "complex_opt_model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "complex_opt_model.add(layers.Dropout(0.2))\n",
    "#deep\n",
    "complex_opt_model.add(layers.Flatten())\n",
    "complex_opt_model.add(layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_lambda)))\n",
    "complex_opt_model.add(layers.BatchNormalization())\n",
    "complex_opt_model.add(layers.Dropout(0.2))\n",
    "complex_opt_model.add(layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_lambda)))\n",
    "complex_opt_model.add(layers.BatchNormalization())\n",
    "complex_opt_model.add(layers.Dropout(0.2))\n",
    "complex_opt_model.add(layers.Dense(10))\n",
    "complex_opt_model.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m, \u001B[38;5;34m30\u001B[0m, \u001B[38;5;34m96\u001B[0m)     │        \u001B[38;5;34m10,464\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m, \u001B[38;5;34m30\u001B[0m, \u001B[38;5;34m96\u001B[0m)     │           \u001B[38;5;34m384\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m, \u001B[38;5;34m30\u001B[0m, \u001B[38;5;34m96\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m, \u001B[38;5;34m30\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │       \u001B[38;5;34m307,328\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m, \u001B[38;5;34m30\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │           \u001B[38;5;34m512\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m, \u001B[38;5;34m30\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │       \u001B[38;5;34m295,168\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │         \u001B[38;5;34m1,024\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │       \u001B[38;5;34m590,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │         \u001B[38;5;34m1,024\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001B[38;5;33mDropout\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │       \u001B[38;5;34m590,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m14\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │         \u001B[38;5;34m1,024\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m, \u001B[38;5;34m6\u001B[0m, \u001B[38;5;34m256\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001B[38;5;33mDropout\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m, \u001B[38;5;34m6\u001B[0m, \u001B[38;5;34m256\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001B[38;5;33mFlatten\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m9216\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)            │     \u001B[38;5;34m4,719,104\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)            │         \u001B[38;5;34m2,048\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001B[38;5;33mDropout\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │       \u001B[38;5;34m131,328\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │         \u001B[38;5;34m1,024\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001B[38;5;33mDropout\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │         \u001B[38;5;34m2,570\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">307,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9216</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m6,653,162\u001B[0m (25.38 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,653,162</span> (25.38 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m6,649,642\u001B[0m (25.37 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,649,642</span> (25.37 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m3,520\u001B[0m (13.75 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,520</span> (13.75 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T08:41:31.793113Z",
     "start_time": "2024-04-30T08:41:31.779836Z"
    }
   },
   "source": [
    "complex_opt_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T08:41:35.643196Z",
     "start_time": "2024-04-30T08:41:35.638319Z"
    }
   },
   "source": [
    "# history dictionary for successive combined trainings\n",
    "combined_complex_opt_history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T08:41:40.280975Z",
     "start_time": "2024-04-30T08:41:40.276790Z"
    }
   },
   "source": [
    "# save history data to disk\n",
    "import json\n",
    "# Save the dictionary to disk using JSON\n",
    "with open('combined_history_complex_model.json', 'w') as f:\n",
    "    json.dump(combined_complex_opt_history, f)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load history data from disk\n",
    "import json\n",
    "\n",
    "with open('combined_history_complex_model.json', 'r') as f:\n",
    "    combined_complex_opt_history = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-04-30T08:41:46.940418Z"
    }
   },
   "source": [
    "# train\n",
    "history = complex_opt_model.fit(training_data, epochs=10, \n",
    "                           validation_data=validation_data)\n",
    "# Update the combined_history with the first training session\n",
    "for key in combined_complex_opt_history.keys():\n",
    "    combined_complex_opt_history[key].extend(history.history[key])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m  1/351\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m28:12\u001B[0m 5s/step - accuracy: 0.1250 - loss: 2.9334"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 10:41:51.632184: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34560000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m  2/351\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:38\u001B[0m 628ms/step - accuracy: 0.1094 - loss: 2.9412"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 10:41:52.239894: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34560000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m  3/351\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:36\u001B[0m 623ms/step - accuracy: 0.1076 - loss: 2.9149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 10:41:52.860182: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34560000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m  4/351\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:30\u001B[0m 606ms/step - accuracy: 0.1178 - loss: 2.8671"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 10:41:53.446781: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34560000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m  5/351\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m3:26\u001B[0m 598ms/step - accuracy: 0.1218 - loss: 2.8644"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 10:41:54.023968: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34560000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m240s\u001B[0m 671ms/step - accuracy: 0.2675 - loss: 2.3163 - val_accuracy: 0.1099 - val_loss: 5.8152\n",
      "Epoch 2/10\n",
      "\u001B[1m351/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m236s\u001B[0m 671ms/step - accuracy: 0.4549 - loss: 1.6615 - val_accuracy: 0.1146 - val_loss: 10.3986\n",
      "Epoch 3/10\n",
      "\u001B[1m325/351\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m16s\u001B[0m 618ms/step - accuracy: 0.5537 - loss: 1.3524"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plott accuracy\n",
    "plt.plot(combined_complex_opt_history['accuracy'], label='accuracy')\n",
    "plt.plot(combined_complex_opt_history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot error\n",
    "plt.plot(combined_complex_opt_history['loss'], label = 'loss')\n",
    "plt.plot(combined_complex_opt_history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"validation data\",complex_model.evaluate(training_data))\n",
    "print(\"validation data\",complex_model.evaluate(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to disk\n",
    "complex_opt_model.save(\"complex_model_opt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "complex_opt_model = tf.keras.models.load_model('complex_model_opt')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantification of the model performance\n",
    "\n",
    "s) Calculate the classification metrics Precision, Recall, F1 for the optimized model.\n",
    "Use the material discussed in AI-Foundation or read articles on the web, for example: \n",
    "https://www.evidentlyai.com/classification-metrics ,\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "\n",
    "t) Estimate the generalization error using k-fold Cross-Validation (CV) with k>=4. Report mean and \n",
    "std-dev of the generalization error (both, loss and accuracy). Compare these values with the \n",
    "previously reported loss and accuracy. Note: for CV, you create different splits of train_val_...\n",
    "You still don't touch the test-set!\n",
    "Optional:\n",
    "Use CV to compare/select hyper-parameters (for example, find an optimal lambda): \n",
    "https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "u) Finally: evaluate the model performance using the test-set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
